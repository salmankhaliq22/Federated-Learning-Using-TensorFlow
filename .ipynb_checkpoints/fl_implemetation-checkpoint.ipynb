{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8467ca6e-2128-4091-8bb0-1c3e1800d958",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "[Federated Learning: A Step by Step Implementation in Tensorflow](https://towardsdatascience.com/federated-learning-a-step-by-step-implementation-in-tensorflow-aac568283399)   \n",
    "Quality data exist as islands on edge devices like mobile phones and personal computers across the globe and are guarded by strict privacy preserving laws. Federated Learning provides a clever means of connecting machine learning models to these disjointed data regardless of their locations, and more importantly, without breaching privacy laws. Rather than taking the data to the model for training as per rule of thumb, FL takes the model to the data instead. All that’s needed is the wiliness of the device hosting the data to commit it’s self to the federation process. \n",
    "\n",
    "The FL architecture in it’s basic form consists of a curator or server that sits at its centre and coordinates the training activities. Clients are mainly edge devices which could run into millions in number. These devices communicate at least twice with the server per training iteration. To start with, they each receive the current global model’s weights from the server, train it on each of their local data to generate updated parameters which are then uploaded back to the server for aggregation. This cycle of communication persists until a pre-set epoch number or an accuracy condition is reached. ``In the Federated Averaging Algorithm, aggregation simply means an averaging operation``. That is all there is to the training of a FL model. I hope you caught the most salient point in the process — rather than moving raw data around, we now communicate model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82604f8b-7518-4b50-b3a8-b4cbff524ad5",
   "metadata": {},
   "source": [
    "## 1. Import all relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f0531d-a67b-47d1-877d-676f9bd17cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# from fl_mnist_implementation_tutorial_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1767c3c-c58e-444a-b40f-e58128cda2bf",
   "metadata": {},
   "source": [
    "## 2. Reading and preprocessing MNIST data set\n",
    "\n",
    "I’m using the jpeg version of MNIST data set from [here](https://www.kaggle.com/datasets/scolianni/mnistasjpg). It consists of 42000 digit images with each class kept in separate folder. I will load the data into memory using this code snippet and keep 10% of the data for testing the trained global model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9bfb88d-ad4d-4e1f-b930-1f12f488601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(paths, verbose=-1):\n",
    "    '''\n",
    "    expects images for each class in seperate dir, \n",
    "    e.g all digits in 0 class in the directory named 0 \n",
    "    '''\n",
    "    data = list()\n",
    "    labels = list()\n",
    "    \n",
    "    # loop over the input images\n",
    "    for (i, imgpath) in enumerate(paths):\n",
    "        \n",
    "        # load the image and extract the class labels\n",
    "        im_gray = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.array(im_gray).flatten()\n",
    "        label = imgpath.split(os.path.sep)[-2]\n",
    "        \n",
    "        # scale the image to [0, 1] and add to list\n",
    "        data.append(image/255)\n",
    "        labels.append(label)\n",
    "        \n",
    "        # show an update every `verbose` images\n",
    "        if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(paths)))\n",
    "    \n",
    "    # return a tuple of the data and labels\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d96d36-6b1b-42fe-a675-80bf2141454b",
   "metadata": {},
   "source": [
    "## Creating train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbec2709-6bbb-4d54-94ba-444b170aa46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10000/42000\n",
      "[INFO] processed 20000/42000\n",
      "[INFO] processed 30000/42000\n",
      "[INFO] processed 40000/42000\n"
     ]
    }
   ],
   "source": [
    "#declear path to your mnist data folder\n",
    "img_path = './data/trainingSet'\n",
    "\n",
    "#get the path list using the path object\n",
    "image_paths = list(paths.list_images(img_path))\n",
    "\n",
    "#apply our function\n",
    "image_list, label_list = load(image_paths, verbose=10000)\n",
    "\n",
    "#binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "label_list = lb.fit_transform(label_list)\n",
    "\n",
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_list, \n",
    "                                                    label_list, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227091ee-9a4b-4c1e-9b89-223e4ac62042",
   "metadata": {},
   "source": [
    "A couple of steps took place in this snippet. We applied the load function defined in the previous code block to obtain the list of images (now in numpy arrays) and label lists. After that, we used the ``LabelBinarizer`` object from sklearn to 1-hot-encode the labels. Going forward, rather than having the label for digit 1 as number 1, it will now have the form``[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]``. With this labelling style, we’ll be able to use the ``cross-entropy`` loss in Tensorflow as our model’s loss function. Alternatively, I could have left the labels as it was and use the ``sparse-categorical-entropy`` loss instead. Finally, I used the sklearn’s ``train_test_split`` object to split the data into a train/test with ratio ``9:1``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b0e7c-06bf-43cb-bbec-525f9763468b",
   "metadata": {},
   "source": [
    "## 3. Federated Members (clients) as Data Shards\n",
    "\n",
    "In the real world implementation of FL, each federated member will have its own data coupled with it in isolation. Remember the aim of FL is to ship models to data and not the other way around. The shard creation step here only happens in experiments. I will share the training set into 10 shards, one per client. I wrote a function called ``create_clients`` to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0870359a-234e-4cca-bbcd-88a8e6d6a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b4114-86ca-4c2a-a42b-d8726e3787c8",
   "metadata": {},
   "source": [
    "On line 13, I created a list of client names using the prefix (``initials``). On line 16–20, I zipped the data and label lists then randomised the resulting tuple list. Finally I created shards from the tuple list based on the desired number of clients (``num_clients``) on line 21. On line 26, a dictionary containing each client’s name as key and their data share as value was returned. Let’s now go ahead and apply this function to our training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f9e35-481b-40c6-9302-0c11c367c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "clients = create_clients(X_train, y_train, num_clients=10, initial='client')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080691ae-d7ef-4340-95c2-0627db2564eb",
   "metadata": {},
   "source": [
    "## 4. Processing and batching clients’ and test data\n",
    "\n",
    "Next is to process each of the client’s data into tensorflow data set and batch them. To simplify this step and avoid repetition, I encapsulated the procedure into a small function named ``batch_data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b053bdf6-0e79-4f82-bff9-273ab655eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data_shard, bs=32):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f68fe3-b1c2-46a9-b4d3-60908414df61",
   "metadata": {},
   "source": [
    "I trust you remember that each of the client data sets came out as a (data, label) tuple list from ``create_clients``. On line 9 above, I split the tuple into separate data and label lists. I then made a shuffled and batched tensorflow dataset object off these lists.\n",
    "\n",
    "While applying this function below, I will process the test set as well and keep it aside for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6a00ca-4e20-44bd-9a95-c1e90098d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c728d3-20e3-465e-8895-54563f9f0854",
   "metadata": {},
   "source": [
    "## 5. Creating the Multi Layer Perceptron (MLP) model\n",
    "\n",
    "One thing I didn't mention in the introduction section is that FL is mostly suited for parameterized learning — all types of neural networks. Machine learning techniques such as KNN or it likes that merely store training data while learning might not benefit from FL. I’m creating a 3-layer MLP to serve as the model for our classification task. I hope you still remember all those Keras modules we imported earlier, this is where they fit in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bfaa440-6ab9-4b1d-9868-e303cc35b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, input_shape=(shape,)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae3790-53cf-4dc5-92a2-221361e3cd56",
   "metadata": {},
   "source": [
    "To build a new model, the ``build`` method will be invoked. It requires the input data’s shape and the number of classes as arguments. With MNIST, the shape parameter will be ``28*28*1 = 784``,while the number of classes will be 10.\n",
    "\n",
    "Now is the time to define an ``optimizer``, ``loss`` function and ``metrics`` to compile our models with later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585e6c46-2e61-4511-bf2b-212027ae808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01 \n",
    "comms_round = 100\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = SGD(lr=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.9\n",
    "               )                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea01e9c-e19f-4245-9566-e038a5cb97e0",
   "metadata": {},
   "source": [
    "SGD is my default optimizer except when I have a reason not to use it. The loss function is ``categorical_crossentropy``. And finally, the metric I will be using is ``accuracy``. But something looks strange in the decay argument. What’s ``comms_round``? It’s simply the number global epochs (aggregations) I will be running during training. So rather than decaying the learning rate with respect to the number of local epochs as you might be familiar with, here I want to decay with respect to the number of global aggregation. This is obviously an hyper parameter selection choice, but I found it to work pretty well while experimenting. I also found an academic report where this setting worked too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22825180-0ebc-4f1f-8a19-ac7932a3e35d",
   "metadata": {},
   "source": [
    "## 6. Model Aggregation (Federated Averaging)\n",
    "\n",
    "All I have done up to this point was pretty much standard as per deep learning pipeline. Of course with the exception of the data partitioning or client creation bit. I will now move on to Federated Averaging ( the vanilla algorithm for FL) which is the whole point of the this tutorial. The data I’m using is horizontally partitioned, so I will simply be doing component wise parameter averaging which will be weighed based on the proportion of data points contributed by each participating client. Here’s the federated averaging equation I’m using, it comes one of the pioneering works on federated learning.\n",
    "\n",
    "![FL_Math](./pics/FL_Math.PNG)\n",
    "\n",
    "\n",
    "Don’t let the complex mathematical notations in the equation fool you, this is a pretty straight forward computation. On the right hand side, we are estimating the weight parameters for each client based on the loss values recorded across every data point they trained with. On the left, we scaled each of those parameters and sum them all component-wise.\n",
    "\n",
    "Below I have encapsulated this procedure into three simple functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005ccd66-64c2-4788-8c63-35148908932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbadf1-26b7-4881-a8fd-3905f60993ec",
   "metadata": {},
   "source": [
    "- ``weight_scalling_factor`` calculates the proportion of a client’s local training data with the overall training data held by all clients. First we obtained the client’s batch size and used that to calculate its number of data points. We then obtained the overall global training data size on line 6. Finally we calculated the scaling factor as a fraction on line 9. This sure can’t be the approach in a real world application. The training data will be disjointed, therefore no single client can correctly estimate the quantity of the combined set. In that case, each client will be expected to indicate the number of data points they trained with while updating the server with new parameters after each local training step.\n",
    "\n",
    "- ``scale_model_weights`` scales each of the local model’s weights based the value of their scaling factor calculated in (1)\n",
    "\n",
    "- ``sum_scaled_weights`` sums all clients’ scaled weights together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b282e045-418e-4034-b6a6-486a91110be4",
   "metadata": {},
   "source": [
    "## 7. Federated Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224b9e7c-aaa8-48d9-9bb1-082cdc05bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comm_round: 0 | global_acc: 88.119% | global_loss: 1.6671500205993652\n",
      "comm_round: 1 | global_acc: 90.857% | global_loss: 1.6128145456314087\n",
      "comm_round: 2 | global_acc: 92.095% | global_loss: 1.593142032623291\n",
      "comm_round: 3 | global_acc: 92.595% | global_loss: 1.581800103187561\n",
      "comm_round: 4 | global_acc: 93.595% | global_loss: 1.5718557834625244\n",
      "comm_round: 5 | global_acc: 93.738% | global_loss: 1.5659619569778442\n",
      "comm_round: 6 | global_acc: 94.048% | global_loss: 1.560738205909729\n",
      "comm_round: 7 | global_acc: 94.405% | global_loss: 1.5559614896774292\n",
      "comm_round: 8 | global_acc: 94.429% | global_loss: 1.5528357028961182\n",
      "comm_round: 9 | global_acc: 94.738% | global_loss: 1.5495578050613403\n",
      "comm_round: 10 | global_acc: 94.833% | global_loss: 1.546671748161316\n",
      "comm_round: 11 | global_acc: 94.857% | global_loss: 1.5443238019943237\n",
      "comm_round: 12 | global_acc: 94.952% | global_loss: 1.5420708656311035\n",
      "comm_round: 13 | global_acc: 95.095% | global_loss: 1.5399842262268066\n",
      "comm_round: 14 | global_acc: 95.167% | global_loss: 1.5389245748519897\n",
      "comm_round: 15 | global_acc: 95.167% | global_loss: 1.5368300676345825\n",
      "comm_round: 16 | global_acc: 95.333% | global_loss: 1.5357990264892578\n",
      "comm_round: 17 | global_acc: 95.429% | global_loss: 1.533823013305664\n",
      "comm_round: 18 | global_acc: 95.452% | global_loss: 1.5328158140182495\n",
      "comm_round: 19 | global_acc: 95.619% | global_loss: 1.5319501161575317\n",
      "comm_round: 20 | global_acc: 95.548% | global_loss: 1.5307188034057617\n",
      "comm_round: 21 | global_acc: 95.714% | global_loss: 1.5296682119369507\n",
      "comm_round: 22 | global_acc: 95.714% | global_loss: 1.5290682315826416\n",
      "comm_round: 23 | global_acc: 95.786% | global_loss: 1.5279903411865234\n",
      "comm_round: 24 | global_acc: 96.048% | global_loss: 1.5277280807495117\n",
      "comm_round: 25 | global_acc: 95.857% | global_loss: 1.5265158414840698\n",
      "comm_round: 26 | global_acc: 96.024% | global_loss: 1.5259090662002563\n",
      "comm_round: 27 | global_acc: 95.833% | global_loss: 1.525168538093567\n",
      "comm_round: 28 | global_acc: 96.000% | global_loss: 1.5247019529342651\n",
      "comm_round: 29 | global_acc: 96.095% | global_loss: 1.5240800380706787\n",
      "comm_round: 30 | global_acc: 96.119% | global_loss: 1.5235512256622314\n",
      "comm_round: 31 | global_acc: 96.071% | global_loss: 1.5229723453521729\n",
      "comm_round: 32 | global_acc: 96.095% | global_loss: 1.5230108499526978\n",
      "comm_round: 33 | global_acc: 96.214% | global_loss: 1.522276759147644\n",
      "comm_round: 34 | global_acc: 96.262% | global_loss: 1.5216574668884277\n",
      "comm_round: 35 | global_acc: 96.214% | global_loss: 1.5215234756469727\n",
      "comm_round: 36 | global_acc: 96.214% | global_loss: 1.5208163261413574\n",
      "comm_round: 37 | global_acc: 96.262% | global_loss: 1.5206794738769531\n",
      "comm_round: 38 | global_acc: 96.333% | global_loss: 1.5200265645980835\n",
      "comm_round: 39 | global_acc: 96.286% | global_loss: 1.5197817087173462\n",
      "comm_round: 40 | global_acc: 96.262% | global_loss: 1.519443154335022\n",
      "comm_round: 41 | global_acc: 96.357% | global_loss: 1.5194021463394165\n",
      "comm_round: 42 | global_acc: 96.310% | global_loss: 1.5191317796707153\n",
      "comm_round: 43 | global_acc: 96.333% | global_loss: 1.51862370967865\n",
      "comm_round: 44 | global_acc: 96.310% | global_loss: 1.517975926399231\n",
      "comm_round: 45 | global_acc: 96.476% | global_loss: 1.5178653001785278\n",
      "comm_round: 46 | global_acc: 96.405% | global_loss: 1.517608404159546\n",
      "comm_round: 47 | global_acc: 96.595% | global_loss: 1.5172700881958008\n",
      "comm_round: 48 | global_acc: 96.500% | global_loss: 1.5171409845352173\n",
      "comm_round: 49 | global_acc: 96.500% | global_loss: 1.5167222023010254\n",
      "comm_round: 50 | global_acc: 96.500% | global_loss: 1.516532063484192\n",
      "comm_round: 51 | global_acc: 96.595% | global_loss: 1.5162421464920044\n",
      "comm_round: 52 | global_acc: 96.619% | global_loss: 1.5161105394363403\n",
      "comm_round: 53 | global_acc: 96.571% | global_loss: 1.516143798828125\n",
      "comm_round: 54 | global_acc: 96.571% | global_loss: 1.5155558586120605\n",
      "comm_round: 55 | global_acc: 96.548% | global_loss: 1.5154799222946167\n",
      "comm_round: 56 | global_acc: 96.667% | global_loss: 1.5153194665908813\n",
      "comm_round: 57 | global_acc: 96.667% | global_loss: 1.5153241157531738\n",
      "comm_round: 58 | global_acc: 96.571% | global_loss: 1.5148240327835083\n",
      "comm_round: 59 | global_acc: 96.667% | global_loss: 1.514625072479248\n",
      "comm_round: 60 | global_acc: 96.690% | global_loss: 1.5143376588821411\n",
      "comm_round: 61 | global_acc: 96.762% | global_loss: 1.5143420696258545\n",
      "comm_round: 62 | global_acc: 96.690% | global_loss: 1.514147400856018\n",
      "comm_round: 63 | global_acc: 96.738% | global_loss: 1.5140799283981323\n",
      "comm_round: 64 | global_acc: 96.714% | global_loss: 1.513918161392212\n",
      "comm_round: 65 | global_acc: 96.667% | global_loss: 1.5136688947677612\n",
      "comm_round: 66 | global_acc: 96.714% | global_loss: 1.5136125087738037\n",
      "comm_round: 67 | global_acc: 96.738% | global_loss: 1.5134555101394653\n",
      "comm_round: 68 | global_acc: 96.690% | global_loss: 1.5131787061691284\n",
      "comm_round: 69 | global_acc: 96.690% | global_loss: 1.5131642818450928\n",
      "comm_round: 70 | global_acc: 96.762% | global_loss: 1.5128577947616577\n",
      "comm_round: 71 | global_acc: 96.738% | global_loss: 1.5125690698623657\n",
      "comm_round: 72 | global_acc: 96.786% | global_loss: 1.5126739740371704\n",
      "comm_round: 73 | global_acc: 96.810% | global_loss: 1.512494683265686\n",
      "comm_round: 74 | global_acc: 96.786% | global_loss: 1.5124644041061401\n",
      "comm_round: 75 | global_acc: 96.786% | global_loss: 1.5122398138046265\n",
      "comm_round: 76 | global_acc: 96.810% | global_loss: 1.5120760202407837\n",
      "comm_round: 77 | global_acc: 96.786% | global_loss: 1.5119024515151978\n",
      "comm_round: 78 | global_acc: 96.762% | global_loss: 1.51185142993927\n",
      "comm_round: 79 | global_acc: 96.786% | global_loss: 1.511682391166687\n",
      "comm_round: 80 | global_acc: 96.786% | global_loss: 1.5115940570831299\n",
      "comm_round: 81 | global_acc: 96.833% | global_loss: 1.511599063873291\n",
      "comm_round: 82 | global_acc: 96.833% | global_loss: 1.511422038078308\n",
      "comm_round: 83 | global_acc: 96.786% | global_loss: 1.5113048553466797\n",
      "comm_round: 84 | global_acc: 96.833% | global_loss: 1.5111702680587769\n",
      "comm_round: 85 | global_acc: 96.786% | global_loss: 1.5110942125320435\n",
      "comm_round: 86 | global_acc: 96.833% | global_loss: 1.510976791381836\n",
      "comm_round: 87 | global_acc: 96.857% | global_loss: 1.510910987854004\n",
      "comm_round: 88 | global_acc: 96.857% | global_loss: 1.5107872486114502\n",
      "comm_round: 89 | global_acc: 96.810% | global_loss: 1.51066255569458\n",
      "comm_round: 90 | global_acc: 96.857% | global_loss: 1.5106127262115479\n",
      "comm_round: 91 | global_acc: 96.810% | global_loss: 1.510529637336731\n",
      "comm_round: 92 | global_acc: 96.833% | global_loss: 1.510398507118225\n",
      "comm_round: 93 | global_acc: 96.857% | global_loss: 1.5102370977401733\n",
      "comm_round: 94 | global_acc: 96.857% | global_loss: 1.510119915008545\n",
      "comm_round: 95 | global_acc: 96.833% | global_loss: 1.50999116897583\n",
      "comm_round: 96 | global_acc: 96.857% | global_loss: 1.5099968910217285\n",
      "comm_round: 97 | global_acc: 96.857% | global_loss: 1.5098267793655396\n",
      "comm_round: 98 | global_acc: 96.881% | global_loss: 1.5099409818649292\n",
      "comm_round: 99 | global_acc: 96.881% | global_loss: 1.5098552703857422\n"
     ]
    }
   ],
   "source": [
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(784, 10)\n",
    "        \n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(784, 10)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c3d0f-5192-4909-9e79-393828578240",
   "metadata": {},
   "source": [
    "The training logic has two main loops, the outer loop is for the global iteration, the inner is for iterating through client’s local training. There’s an implicit third one though, it accounts for the local epochs and will be taken care of by the epochs argument in our ``model.fit`` method.\n",
    "\n",
    "Starting out I built the global model with input shape of (784,) and number of classes as 10 — lines 2–3. I then stepped into the outer loop. First obtaining the initialised ``weights`` of the global model on line 9. Lines 15 and 16 shuffles the clients dictionary order to ensure randomness. From there, I started iterating through client training.\n",
    "\n",
    "For each client, I created a new model object, compiled it and set it’s initialisation weights to the current parameters of the global model — lines 20–27. The local model (client) was then trained for one epoch. After training, the new weights were scaled and appended to the ``scaled_local_weight_list`` on line 35. That was it for local training.\n",
    "\n",
    "Moving back into the outer loop on line 41, I summed up all the scaled local trained weights (of course by components) and updated the global model to this new aggregate. That ends a full global training epoch.\n",
    "\n",
    "I ran 100 global training loops as stipulated by the ``comms_round`` and on line 48 tested the trained global model after each communication round our test data. Here is the snippet for the test logic:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f2ab6-a48a-4c06-ba8f-27ad6a5039b1",
   "metadata": {},
   "source": [
    "## 8. SGD Vs Federated Averaging\n",
    "Yes, our FL model results are great, 96.5% test accuracy after 100 communication rounds. But how does it compare to a standard SGD model trained on the same data set? To find out, I’ll train a single 3-layer MLP model (rather 10 as we did in FL) on the combined training data. Remember the combined data was our training data prior to partitioning.\n",
    "\n",
    "To ensure an equal playing ground, I will retain every hyper parameter used for the FL training except the batch size. Rather than using 32 , our SGD’s batch size will be 320. With this setting, we are sure that the SGD model would see exactly the same number of training samples per epoch as the global model did per communication round in FL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a58ab3-0e9e-47bf-87a1-d8e21dff80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(320)\n",
    "smlp_SGD = SimpleMLP()\n",
    "SGD_model = smlp_SGD.build(784, 10) \n",
    "\n",
    "SGD_model.compile(loss=loss, \n",
    "              optimizer=optimizer, \n",
    "              metrics=metrics)\n",
    "\n",
    "# fit the SGD training data to model\n",
    "_ = SGD_model.fit(SGD_dataset, epochs=100, verbose=0)\n",
    "\n",
    "#test the SGD global model and print out metrics\n",
    "for(X_test, Y_test) in test_batched:\n",
    "        SGD_acc, SGD_loss = test_model(X_test, Y_test, SGD_model, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f797b9f-725d-4f43-80a3-9082ff02c523",
   "metadata": {},
   "source": [
    "There you have it, a 94.5% test accuracy for the SGD model after 100 epochs. Isn’t it surprising that the FL performed a little better than its SGD counterpart with this data set? I warn you not to get too excited about this though. These kind of results are not likely in real world scenario. Yeah! Real world federated data held by clients are mostly NON independent and identically distributed (IID).\n",
    "\n",
    "For example, we could have replicated this scenario by constructing our client shards above such that each comprises of images from a single class — e.g client_1 having only images of digit 1, client_2 having only images of digit 2 and so on. This arrangement would have lead to a significant reduction in the performance of the FL model. I leave this as an exercise for the reader to try out. Meanwhile, here is the code you could use to shard any classification data in a non-IID manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc14d1-b445-44af-9fab-02cdda8f3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_iid_x(image_list, label_list, x=1, num_intraclass_clients=10):\n",
    "        ''' creates x non_IID clients\n",
    "        args: \n",
    "            image_list: python list of images or data points\n",
    "            label_list: python list of labels\n",
    "            x: none IID severity, 1 means each client will only have one class of data\n",
    "            num_intraclass_client: number of sub-client to be created from each none IID class,\n",
    "            e.g for x=1, we could create 10 further clients by splitting each class into 10\n",
    "            \n",
    "        return - dictionary \n",
    "            keys - clients's name, \n",
    "            value - client's non iid 1 data shard (as tuple list of images and labels) '''\n",
    "        \n",
    "        non_iid_x_clients = dict()\n",
    "        \n",
    "        #create unique label list and shuffle\n",
    "        unique_labels = np.unique(np.array(label_list))\n",
    "        random.shuffle(unique_labels)\n",
    "        \n",
    "        #create sub label lists based on x\n",
    "        sub_lab_list = [unique_labels[i:i + x] for i in range(0, len(unique_labels), x)]\n",
    "            \n",
    "        for item in sub_lab_list:\n",
    "            class_data = [(image, label) for (image, label) in zip(image_list, label_list) if label in item]\n",
    "            \n",
    "            #decouple tuple list into seperate image and label lists\n",
    "            images, labels = zip(*class_data)\n",
    "            \n",
    "            # create formated client initials\n",
    "            initial = ''\n",
    "            for lab in item:\n",
    "                initial = initial + lab + '_'\n",
    "            \n",
    "            #create num_intraclass_clients clients from the class \n",
    "            intraclass_clients = create_clients(list(images), list(labels), num_intraclass_clients, initial)\n",
    "            \n",
    "            #append intraclass clients to main clients'dict\n",
    "            non_iid_x_clients.update(intraclass_clients)\n",
    "        \n",
    "        return non_iid_x_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33888050-b1d1-490b-9867-91f160c76794",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "Through this article, I introduced the concept of Federated Learning and took you through the tensorflow implementation of it basic form. I encourage you to check my recent article on LinkedIn here for broader introduction of this technology, particularly if you are not clear about its workings or want to learn more about how it could be applied. For researchers wanting to study this subject in more depth, there are lots of journals around FL on arxiv.org/cs , mostly pushing boundaries on its implementation and addressing its numerous challenges.\n",
    "\n",
    "## 10. Reference\n",
    "[1] Federated Learning with Non-IID Data, Yue Zhao et al, arXiv: 1806.00582v1, 2 Jun 2018\n",
    "\n",
    "[2] Communication-Efficient Learning of Deep Networks from Decentralized Data, H. Brendan McMahan et al, arXiv:1602.05629v3 [cs.LG] 28 Feb 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e1abe-8ca1-4125-9514-68ec493c2d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
